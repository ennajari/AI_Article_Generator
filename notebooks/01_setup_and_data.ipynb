{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2cd0da5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OllamaEmbeddings\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f05b5148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📌 2. Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# 📌 3. Define paths\n",
    "DATA_FILE = \"../data/sample_docs.txt\"\n",
    "VECTOR_STORE_DIR = \"../data/faiss_store\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fdbd5e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Loading and splitting documents...\n"
     ]
    }
   ],
   "source": [
    "# 📌 4. Load and split documents\n",
    "print(\"🔄 Loading and splitting documents...\")\n",
    "loader = TextLoader(DATA_FILE)\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e214c8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=50\n",
    ")\n",
    "texts = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2f92fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 2 chunks created.\n"
     ]
    }
   ],
   "source": [
    "print(f\"✅ {len(texts)} chunks created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "140e96b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Initializing Ollama embeddings...\n"
     ]
    }
   ],
   "source": [
    "# 📌 5. Initialize Ollama embeddings\n",
    "print(\"🔍 Initializing Ollama embeddings...\")\n",
    "embedding_model = OllamaEmbeddings(model=\"nomic-embed-text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4d6b4b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📌 6. Create or update FAISS vector store\n",
    "if os.path.exists(VECTOR_STORE_DIR):\n",
    "    shutil.rmtree(VECTOR_STORE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f32c7c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Building vector store...\n"
     ]
    }
   ],
   "source": [
    "print(\"💾 Building vector store...\")\n",
    "db = FAISS.from_documents(texts, embedding_model)\n",
    "db.save_local(VECTOR_STORE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f8a8a1a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Vector store created and saved at: ../data/faiss_store\n",
      "\n",
      "📚 Retrieved documents for test query:\n",
      "\n",
      "--- Document 1 ---\n",
      "Natural language processing (NLP) allows AI systems to extract valuable insights from unstructured medical records and research papers.\n",
      "Wearable devices integrated with AI monitor patient vitals in real-time, alerting healthcare providers to potential issues before they escalate.\n",
      "\n",
      "--- Document 2 ---\n",
      "AI is revolutionizing healthcare by enabling faster and more accurate diagnostics through advanced image recognition algorithms.\n",
      "Machine learning models can analyze patient data to predict disease progression, helping doctors create personalized treatment plans.\n",
      "Hospitals are using AI-powered tools to optimize resource allocation, reducing wait times and improving patient care efficiency.\n"
     ]
    }
   ],
   "source": [
    "print(\"✅ Vector store created and saved at:\", VECTOR_STORE_DIR)\n",
    "\n",
    "# 📌 7. Test a simple similarity search\n",
    "query = \"What is Retrieval-Augmented Generation?\"\n",
    "retrieved_docs = db.similarity_search(query, k=2)\n",
    "\n",
    "print(\"\\n📚 Retrieved documents for test query:\")\n",
    "for i, doc in enumerate(retrieved_docs):\n",
    "    print(f\"\\n--- Document {i+1} ---\\n{doc.page_content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf86981",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
